Improving the player experience has been the main goal of game designers since the beginning of the computer games industry. A plethora of techniques have been used into try to achieve this, of which some approaches  have proven to be very effective, and others less so.

In this study we propose two variations on a game designed to improve player experience, and use both AI agents and testing with human players to try to demonstrate that the game variants improve the player experience. For the AI agents, a number of metrics are recorded from AI versus AI gameplay, and some simple analytics used to see if the intended impact is achieved. We then use human players to try to confirm these results, and to try to demonstrate the usefulness of using analytics over AI gameplay to measuring the impact to changes on videogames.

is an attempt to reach the very same purpose, using artificial intelligence and play testing as primary means of analysis. The goal is to prove that some modifications to the classical Asteroids Battle game can indeed make the game more enjoyable for players.
In the first instance, intelligent agents were used to play the game and a number of game metrics and analytics were measured / employed in order to quantify their experience. In the second part of the project, human players were asked to participate in an experiment, playing three different versions of the game, one being the classical battle, and the other two versions containing incremental modifications and increased complexity. The human players were asked to fill in a questionnaire while playing through each version of the game, in order to understand their gaming experience and their responses to the changes in the mechanics of the game brought by the modified versions.
